{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM and Neural Network Approach to Target Ratio Prediction\n",
    "-Team Abraca_dataIITKGP.\n",
    "Team members:\n",
    "Nikhil Mantri, Tanmay Das, Aniket Shah, Devansh Pandey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We designed a time series data combined with Neural Network approach to Target ratio Prediction\n",
    "First of all we needed to arrange the data in feature_00 till feature_60 of every type(ER1, ER2, ER3, MI1, MI2) in an order of time series. To do this, we hypothesised that the dependence of target ratio will be higher on yesterday than the days before yesterday and extrapolated the logic to the n days(n=60 here) before it. So highest covraince day is the 60th day, next highest 59th and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then took 1-59 days as our train data vectors in sequence row-wise and 60th day as the target into a custom LSTM network defined as regressor in the following cells. So each type has its regressor. And these regressors will be seperately defined and trained on the train and test dataset. Next create feature_ratio_type(0 till 5) by outpitting the corresponding prediction of a type on \"(60+span[i] day)/60th day\" by using our LSTM trained for each type on each of the train and test dataset.\n",
    "This we are terming as feature ratios. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later we put these six ultimate features in a custom dense neural network trained on these 6 train feature ratios and target ratio as the target variable for 100000 epochs, batch_size=16. We standard scale the data before putting it in our neural network and inverse tranform the output that is fit for submission .\n",
    "We achieved a stagarring leaderboard score of (0.984214) which was e raised to -ve of RMSE value on test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "# import warnings \n",
    "df_original=pd.read_csv(\"weights/train.csv\")\n",
    "train = pd.read_csv(\"weights/train.csv')\n",
    "test=pd.read_csv(\"weights/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = ['id','span','target']\n",
    "for i in range(0, 6):\n",
    "#     pd.concat([train.iloc[:,2:3],train.iloc[:,65:67]], axis=1)\n",
    "    a = np.array(pd.concat([train.iloc[:,2:3], train.iloc[:,(3+i*60):(3+(i+1)*60)]], axis=1).cov()['target'].drop(['target']).sort_values().index)\n",
    "    t = np.append(t, values=a)\n",
    "train_sequence = train[t]\n",
    "test_sequence = test[np.delete(t, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in  train_sequence.columns:\n",
    "    train_sequence[col] = pd.to_numeric(train_sequence[col], errors='coerce')\n",
    "\n",
    "    \n",
    "for col in  test_sequence.columns:\n",
    "    test_sequence[col] = pd.to_numeric(test_sequence[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling missing values\n",
    "for col in train_sequence.columns:\n",
    "    if train_sequence[col].isnull().sum()>0:\n",
    "        train_sequence[col].fillna(train_sequence[col].mean,inplace=True)\n",
    "        \n",
    "#filling missing values\n",
    "for col in test_sequence.columns:\n",
    "    if test_sequence[col].isnull().sum()>0:\n",
    "        test_sequence[col].fillna(test_sequence[col].mean,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=1000, step=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sequence_transpose = train_sequence.T\n",
    "train_sequence_transpose.columns\n",
    "\n",
    "test_sequence_transpose = test_sequence.T\n",
    "test_sequence_transpose.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #\n",
    "# #For train dataset\n",
    "\n",
    "# type_00 = []\n",
    "# type_01 = []\n",
    "# type_02 = []\n",
    "# type_03 = []\n",
    "# type_04 = []\n",
    "# type_05 = []\n",
    "# for i in range(test_sequence.shape[0]):\n",
    "#     type_00.append(train_sequence_transpose[i][2:61])\n",
    "#     type_01.append(train_sequence_transpose[i][62:121])\n",
    "#     type_02.append(train_sequence_transpose[i][122:181])\n",
    "#     type_03.append(train_sequence_transpose[i][182:241])\n",
    "#     type_04.append(test_sequence_transpose[i][242:301])\n",
    "#     type_05.append(train_sequence_transpose[i][302:361])\n",
    "    \n",
    "# import numpy as np\n",
    "# type_00 = np.array(type_00)\n",
    "# type_01 = np.array(type_01)\n",
    "# type_02 = np.array(type_02)\n",
    "# type_03 = np.array(type_03)\n",
    "# type_04 = np.array(type_04)\n",
    "# type_05 = np.array(type_05)\n",
    "# type_00 = type_00.reshape((train_sequence.shape[0], 59))\n",
    "# type_01 = type_01.reshape((train_sequence.shape[0], 59))\n",
    "# type_02 = type_02.reshape((train_sequence.shape[0], 59))\n",
    "# type_03 = type_03.reshape((train_sequence.shape[0], 59))\n",
    "# type_04 = type_04.reshape((train_sequence.shape[0], 59))\n",
    "# type_05 = type_05.reshape((train_sequence.shape[0], 59))\n",
    "\n",
    "# type_00_target = []\n",
    "# type_01_target = []\n",
    "# type_02_target = []\n",
    "# type_03_target = []\n",
    "# type_04_target = []\n",
    "# type_05_target = []\n",
    "# for i in range(test_sequence.shape[0]):\n",
    "#     type_00_target.append(test_sequence_transpose[i][61])\n",
    "#     type_01_target.append(test_sequence_transpose[i][121])\n",
    "#     type_02_target.append(test_sequence_transpose[i][181])\n",
    "#     type_03_target.append(test_sequence_transpose[i][241])\n",
    "#     type_04_target.append(test_sequence_transpose[i][301])\n",
    "#     type_05_target.append(test_sequence_transpose[i][361])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#For test dataset\n",
    "\n",
    "type_00 = []\n",
    "type_01 = []\n",
    "type_02 = []\n",
    "type_03 = []\n",
    "type_04 = []\n",
    "type_05 = []\n",
    "for i in range(test_sequence.shape[0]):\n",
    "    type_00.append(test_sequence_transpose[i][2:61])\n",
    "    type_01.append(test_sequence_transpose[i][62:121])\n",
    "    type_02.append(test_sequence_transpose[i][122:181])\n",
    "    type_03.append(test_sequence_transpose[i][182:241])\n",
    "    type_04.append(test_sequence_transpose[i][242:301])\n",
    "    type_05.append(test_sequence_transpose[i][302:361])\n",
    "    \n",
    "import numpy as np\n",
    "type_00 = np.array(type_00)\n",
    "type_01 = np.array(type_01)\n",
    "type_02 = np.array(type_02)\n",
    "type_03 = np.array(type_03)\n",
    "type_04 = np.array(type_04)\n",
    "type_05 = np.array(type_05)\n",
    "type_00 = type_00.reshape((test_sequence.shape[0], 59))\n",
    "type_01 = type_01.reshape((test_sequence.shape[0], 59))\n",
    "type_02 = type_02.reshape((test_sequence.shape[0], 59))\n",
    "type_03 = type_03.reshape((test_sequence.shape[0], 59))\n",
    "type_04 = type_04.reshape((test_sequence.shape[0], 59))\n",
    "type_05 = type_05.reshape((test_sequence.shape[0], 59))\n",
    "\n",
    "type_00_target = []\n",
    "type_01_target = []\n",
    "type_02_target = []\n",
    "type_03_target = []\n",
    "type_04_target = []\n",
    "type_05_target = []\n",
    "for i in range(test_sequence.shape[0]):\n",
    "    type_00_target.append(test_sequence_transpose[i][61])\n",
    "    type_01_target.append(test_sequence_transpose[i][121])\n",
    "    type_02_target.append(test_sequence_transpose[i][181])\n",
    "    type_03_target.append(test_sequence_transpose[i][241])\n",
    "    type_04_target.append(test_sequence_transpose[i][301])\n",
    "    type_05_target.append(test_sequence_transpose[i][361])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "type_00 = np.reshape(type_00, (type_00.shape[0], type_00.shape[1], 1))\n",
    "type_01 = np.reshape(type_01, (type_01.shape[0], type_01.shape[1], 1))\n",
    "type_02 = np.reshape(type_02, (type_02.shape[0], type_02.shape[1], 1))\n",
    "type_03 = np.reshape(type_03, (type_03.shape[0], type_03.shape[1], 1))\n",
    "type_04 = np.reshape(type_04, (type_04.shape[0], type_04.shape[1], 1))\n",
    "type_05 = np.reshape(type_05, (type_05.shape[0], type_05.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(type_00[0])):      \n",
    "    for i in range(len(type_00)):\n",
    "        for k in range(len(type_00[0][0])):            \n",
    "            if type(type_00[0][0][0])!=type(type_00[i][j][k]):\n",
    "                type_00[i][j][k]=0\n",
    "                                    \n",
    "for j in range(len(type_01[0])):      \n",
    "    for i in range(len(type_01)):\n",
    "        for k in range(len(type_01[0][0])):            \n",
    "            if type(type_01[0][0][0])!=type(type_01[i][j][k]):\n",
    "                type_01[i][j][k]=0\n",
    "                                        \n",
    "for j in range(len(type_02[0])):      \n",
    "    for i in range(len(type_02)):\n",
    "        for k in range(len(type_02[0][0])):            \n",
    "            if type(type_02[0][0][0])!=type(type_02[i][j][k]):\n",
    "                type_02[i][j][k]=0\n",
    "\n",
    "for j in range(len(type_03[0])):      \n",
    "    for i in range(len(type_03)):\n",
    "        for k in range(len(type_03[0][0])):            \n",
    "            if type(type_03[0][0][0])!=type(type_03[i][j][k]):\n",
    "                type_03[i][j][k]=0\n",
    "                                            \n",
    "for j in range(len(type_04[0])):      \n",
    "    for i in range(len(type_04)):\n",
    "        for k in range(len(type_04[0][0])):            \n",
    "            if type(type_04[0][0][0])!=type(type_04[i][j][k]):\n",
    "                type_04[i][j][k]=0\n",
    "\n",
    "for j in range(len(type_05[0])):      \n",
    "    for i in range(len(type_05)):\n",
    "        for k in range(len(type_05[0][0])):            \n",
    "            if type(type_05[0][0][0])!=type(type_05[i][j][k]):\n",
    "                type_05[i][j][k]=0\n",
    "\n",
    "###TARGETS###                \n",
    "for i in range(len(type_00_target)):    \n",
    "    if type(type_00_target[0])!=type(type_00_target[i]):        \n",
    "        type_00_target[i]=1\n",
    "\n",
    "for i in range(len(type_01_target)):    \n",
    "    if type(type_01_target[0])!=type(type_01_target[i]):        \n",
    "        type_01_target[i]=1\n",
    "        \n",
    "for i in range(len(type_02_target)):    \n",
    "    if type(type_02_target[0])!=type(type_02_target[i]):        \n",
    "        type_02_target[i]=1\n",
    "        \n",
    "for i in range(len(type_03_target)):    \n",
    "    if type(type_03_target[0])!=type(type_03_target[i]):        \n",
    "        type_03_target[i]=1\n",
    "        \n",
    "for i in range(len(type_04_target)):    \n",
    "    if type(type_04_target[0])!=type(type_04_target[i]):        \n",
    "        type_04_target[i]=1\n",
    "\n",
    "for i in range(len(type_05_target)):    \n",
    "    if type(type_05_target[0])!=type(type_05_target[i]):        \n",
    "        type_05_target[i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regressor = Sequential()\n",
    "\n",
    "# # Adding the first LSTM layer and some Dropout regularisation\n",
    "# regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (59, 1)))\n",
    "# regressor.add(Dropout(0.2))\n",
    "# regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "# regressor.add(Dropout(0.2))\n",
    "# regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "# regressor.add(Dropout(0.2))\n",
    "# regressor.add(LSTM(units = 50))\n",
    "# regressor.add(Dropout(0.2))\n",
    "# regressor.add(Dense(units = 1))\n",
    "# # Compiling the RNN\n",
    "# regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "# # Fitting the RNN to the Training set\n",
    "# regressor.fit(type_00, type_00_target, epochs = 20, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"THIS IS FOR THE TRAIN'S FEATURES HENCE HASHED OUT \"\"\"\n",
    "# import pickle\n",
    "# # pickle.dump(regressor,open(\"weights/regressor00.sav\",\"wb\"))\n",
    "# regressor00=pickle.load(open(\"weights/regressor00.sav\",\"rb\"))\n",
    "# # pickle.dump(regressor,open(\"weights/regressor00.sav\",\"wb\"))\n",
    "# regressor01=pickle.load(open(\"weights/regressor01.sav\",\"rb\"))\n",
    "# # pickle.dump(regressor,open(\"weights/regressor00.sav\",\"wb\"))\n",
    "# regressor02=pickle.load(open(\"weights/regressor02.sav\",\"rb\"))\n",
    "# # pickle.dump(regressor,open(\"weights/regressor00.sav\",\"wb\"))\n",
    "# regressor03=pickle.load(open(\"weights/regressor03.sav\",\"rb\"))\n",
    "# # pickle.dump(regressor,open(\"weights/regressor00.sav\",\"wb\"))\n",
    "# regressor04=pickle.load(open(\"weights/regressor04.sav\",\"rb\"))\n",
    "# # pickle.dump(regressor,open(\"weights/regressor00.sav\",\"wb\"))\n",
    "# regressor05=pickle.load(open(\"weights/regressor05.sav\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# pickle.dump(regressor,open(\"regressor00.sav\",\"wb\"))\n",
    "regressor00=pickle.load(open(\"weights/regressor00_test.sav\",\"rb\"))\n",
    "# pickle.dump(regressor,open(\"regressor00.sav\",\"wb\"))\n",
    "regressor01=pickle.load(open(\"weights/regressor01_test.sav\",\"rb\"))\n",
    "# pickle.dump(regressor,open(\"regressor00.sav\",\"wb\"))\n",
    "regressor02=pickle.load(open(\"weights/regressor02_test.sav\",\"rb\"))\n",
    "# pickle.dump(regressor,open(\"regressor00.sav\",\"wb\"))\n",
    "regressor03=pickle.load(open(\"weights/regressor03_test.sav\",\"rb\"))\n",
    "# pickle.dump(regressor,open(\"regressor00.sav\",\"wb\"))\n",
    "regressor04=pickle.load(open(\"weights/regressor04_test.sav\",\"rb\"))\n",
    "# pickle.dump(regressor,open(\"regressor00.sav\",\"wb\"))\n",
    "regressor05=pickle.load(open(\"weights/regressor05_test.sav\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"THIS IS FOR THE TRAIN'S FEATURES HENCE HASHED OUT \"\"\"\n",
    "# type_00_copy=type_00\n",
    "# ans00=[]\n",
    "# for i in range(len(train_sequence[\"span\"])):\n",
    "#     span_value=train_sequence[\"span\"][i]\n",
    "#     for j in range(span_value+1):\n",
    "#         z=type_00_copy[i][0:59].reshape(1,59,1)\n",
    "#         temp=regressor00.predict(z)\n",
    "#         if(j==0):\n",
    "#             denominator=temp[0][0]\n",
    "#         for k in range(0,58):\n",
    "#             type_00_copy[i][k]=type_00_copy[i][k+1]\n",
    "#         type_00_copy[i][58]=temp\n",
    "#     if(i%100==0):\n",
    "#         print(i,\"done\")\n",
    "#     ans00.append(temp[0][0]/denominator)\n",
    "# print(\"done all\")\n",
    "# print(\"ans00:\",ans00)\n",
    "\n",
    "# type_01_copy=type_01\n",
    "# ans01=[]\n",
    "# for i in range(len(train_sequence[\"span\"])):\n",
    "#     span_value=train_sequence[\"span\"][i]\n",
    "#     for j in range(span_value+1):\n",
    "#         z=type_01_copy[i][0:59].reshape(1,59,1)\n",
    "#         temp=regressor01.predict(z)\n",
    "#         if(j==0):\n",
    "#             denominator=temp[0][0]\n",
    "#         for k in range(0,58):\n",
    "#             type_01_copy[i][k]=type_01_copy[i][k+1]\n",
    "#         type_01_copy[i][58]=temp\n",
    "#     if(i%100==0):\n",
    "#         print(i,\"done\")\n",
    "#     ans01.append(temp[0][0]/denominator)\n",
    "# print(\"done all\")\n",
    "# print(\"ans01:\",ans01)\n",
    "\n",
    "# type_02_copy=type_02\n",
    "# ans02=[]\n",
    "# for i in range(len(train_sequence[\"span\"])):\n",
    "#     span_value=train_sequence[\"span\"][i]\n",
    "#     for j in range(span_value+1):\n",
    "#         z=type_02_copy[i][0:59].reshape(1,59,1)\n",
    "#         temp=regressor02.predict(z)\n",
    "#         if(j==0):\n",
    "#             denominator=temp[0][0]\n",
    "#         for k in range(0,58):\n",
    "#             type_02_copy[i][k]=type_02_copy[i][k+1]\n",
    "#         type_02_copy[i][58]=temp\n",
    "#     if(i%100==0):\n",
    "#         print(i,\"done\")\n",
    "#     ans02.append(temp[0][0]/denominator)\n",
    "# print(\"done all\")\n",
    "# print(\"ans02:\",ans02)\n",
    "\n",
    "# type_03_copy=type_03\n",
    "# ans03=[]\n",
    "# for i in range(len(train_sequence[\"span\"])):\n",
    "#     span_value=train_sequence[\"span\"][i]\n",
    "#     for j in range(span_value+1):\n",
    "#         z=type_03_copy[i][0:59].reshape(1,59,1)\n",
    "#         temp=regressor03.predict(z)\n",
    "#         if(j==0):\n",
    "#             denominator=temp[0][0]\n",
    "#         for k in range(0,58):\n",
    "#             type_03_copy[i][k]=type_03_copy[i][k+1]\n",
    "#         type_03_copy[i][58]=temp\n",
    "#     if(i%100==0):\n",
    "#         print(i,\"done\")\n",
    "#     ans03.append(temp[0][0]/denominator)\n",
    "# print(\"done all\")\n",
    "# print(\"ans03:\",ans03)\n",
    "\n",
    "# type_04_copy=type_04\n",
    "# ans04=[]\n",
    "# for i in range(len(train_sequence[\"span\"])):\n",
    "#     span_value=train_sequence[\"span\"][i]\n",
    "#     for j in range(span_value+1):\n",
    "#         z=type_04_copy[i][0:59].reshape(1,59,1)\n",
    "#         temp=regressor04.predict(z)\n",
    "#         if(j==0):\n",
    "#             denominator=temp[0][0]\n",
    "#         for k in range(0,58):\n",
    "#             type_04_copy[i][k]=type_04_copy[i][k+1]\n",
    "#         type_04_copy[i][58]=temp\n",
    "#     if(i%100==0):\n",
    "#         print(i,\"done\")\n",
    "#     ans04.append(temp[0][0]/denominator)\n",
    "# print(\"done all\")\n",
    "# print(\"ans04:\",ans04)\n",
    "\n",
    "# type_05_copy=type_05\n",
    "# ans05=[]\n",
    "# for i in range(len(train_sequence[\"span\"])):\n",
    "#     span_value=train_sequence[\"span\"][i]\n",
    "#     for j in range(span_value+1):\n",
    "#         z=type_05_copy[i][0:59].reshape(1,59,1)\n",
    "#         temp=regressor05.predict(z)\n",
    "#         if(j==0):\n",
    "#             denominator=temp[0][0]\n",
    "#         for k in range(0,58):\n",
    "#             type_05_copy[i][k]=type_05_copy[i][k+1]\n",
    "#         type_05_copy[i][58]=temp\n",
    "#     if(i%100==0):\n",
    "#         print(i,\"done\")\n",
    "#     ans05.append(temp[0][0]/denominator)\n",
    "# print(\"done all\")\n",
    "# print(\"ans05:\",ans05)\n",
    "\n",
    "# t=pd.DataFrame()\n",
    "# t['id']=test['id']\n",
    "# t['span']=test['span']\n",
    "# t['feature_ratio_type0']=ans00\n",
    "# t['feature_ratio_type1']=ans01\n",
    "# t['feature_ratio_type2']=ans02\n",
    "# t['feature_ratio_type3']=ans03\n",
    "# t['feature_ratio_type4']=ans04\n",
    "# t['feature_ratio_type5']=ans05\n",
    "# t.to_csv(\"competition_data/LSTM_train_feat_ratios.csv\",index=False)\n",
    "\n",
    "\n",
    "# df_LSTM_train=t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #\n",
    "# regressor00.fit(type_00, type_00_target, epochs = 20, batch_size = 32)\n",
    "# regressor01.fit(type_01, type_01_target, epochs = 20, batch_size = 32)\n",
    "# regressor02.fit(type_02, type_02_target, epochs = 20, batch_size = 32)\n",
    "# regressor03.fit(type_03, type_03_target, epochs = 20, batch_size = 32)\n",
    "# regressor04.fit(type_04, type_04_target, epochs = 20, batch_size = 32)\n",
    "# regressor05.fit(type_05, type_05_target, epochs = 20, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_00_copy=type_00\n",
    "ans00=[]\n",
    "for i in range(len(test_sequence[\"span\"])):\n",
    "    span_value=test_sequence[\"span\"][i]\n",
    "    for j in range(span_value+1):\n",
    "        z=type_00_copy[i][0:59].reshape(1,59,1)\n",
    "        temp=regressor00.predict(z)\n",
    "        if(j==0):\n",
    "            denominator=temp[0][0]\n",
    "        for k in range(0,58):\n",
    "            type_00_copy[i][k]=type_00_copy[i][k+1]\n",
    "        type_00_copy[i][58]=temp\n",
    "    if(i%100==0):\n",
    "        print(i,\"done\")\n",
    "    ans00.append(temp[0][0]/denominator)\n",
    "print(\"done all\")\n",
    "print(\"ans00:\",ans00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_01_copy=type_01\n",
    "ans01=[]\n",
    "for i in range(len(test_sequence[\"span\"])):\n",
    "    span_value=test_sequence[\"span\"][i]\n",
    "    for j in range(span_value+1):\n",
    "        z=type_01_copy[i][0:59].reshape(1,59,1)\n",
    "        temp=regressor01.predict(z)\n",
    "        if(j==0):\n",
    "            denominator=temp[0][0]\n",
    "        for k in range(0,58):\n",
    "            type_01_copy[i][k]=type_01_copy[i][k+1]\n",
    "        type_01_copy[i][58]=temp\n",
    "    if(i%100==0):\n",
    "        print(i,\"done\")\n",
    "    ans01.append(temp[0][0]/denominator)\n",
    "print(\"done all\")\n",
    "print(\"ans01:\",ans01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_02_copy=type_02\n",
    "ans02=[]\n",
    "for i in range(len(test_sequence[\"span\"])):\n",
    "    span_value=test_sequence[\"span\"][i]\n",
    "    for j in range(span_value+1):\n",
    "        z=type_02_copy[i][0:59].reshape(1,59,1)\n",
    "        temp=regressor02.predict(z)\n",
    "        if(j==0):\n",
    "            denominator=temp[0][0]\n",
    "        for k in range(0,58):\n",
    "            type_02_copy[i][k]=type_02_copy[i][k+1]\n",
    "        type_02_copy[i][58]=temp\n",
    "    if(i%100==0):\n",
    "        print(i,\"done\")\n",
    "    ans02.append(temp[0][0]/denominator)\n",
    "print(\"done all\")\n",
    "print(\"ans02:\",ans02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_03_copy=type_03\n",
    "ans03=[]\n",
    "for i in range(len(test_sequence[\"span\"])):\n",
    "    span_value=test_sequence[\"span\"][i]\n",
    "    for j in range(span_value+1):\n",
    "        z=type_03_copy[i][0:59].reshape(1,59,1)\n",
    "        temp=regressor03.predict(z)\n",
    "        if(j==0):\n",
    "            denominator=temp[0][0]\n",
    "        for k in range(0,58):\n",
    "            type_03_copy[i][k]=type_03_copy[i][k+1]\n",
    "        type_03_copy[i][58]=temp\n",
    "    if(i%100==0):\n",
    "        print(i,\"done\")\n",
    "    ans03.append(temp[0][0]/denominator)\n",
    "print(\"done all\")\n",
    "print(\"ans03:\",ans03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_04_copy=type_04\n",
    "ans04=[]\n",
    "for i in range(len(test_sequence[\"span\"])):\n",
    "    span_value=test_sequence[\"span\"][i]\n",
    "    for j in range(span_value+1):\n",
    "        z=type_04_copy[i][0:59].reshape(1,59,1)\n",
    "        temp=regressor04.predict(z)\n",
    "        if(j==0):\n",
    "            denominator=temp[0][0]\n",
    "        for k in range(0,58):\n",
    "            type_04_copy[i][k]=type_04_copy[i][k+1]\n",
    "        type_04_copy[i][58]=temp\n",
    "    if(i%100==0):\n",
    "        print(i,\"done\")\n",
    "    ans04.append(temp[0][0]/denominator)\n",
    "print(\"done all\")\n",
    "print(\"ans04:\",ans04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_05_copy=type_05\n",
    "ans05=[]\n",
    "for i in range(len(test_sequence[\"span\"])):\n",
    "    span_value=test_sequence[\"span\"][i]\n",
    "    for j in range(span_value+1):\n",
    "        z=type_05_copy[i][0:59].reshape(1,59,1)\n",
    "        temp=regressor05.predict(z)\n",
    "        if(j==0):\n",
    "            denominator=temp[0][0]\n",
    "        for k in range(0,58):\n",
    "            type_05_copy[i][k]=type_05_copy[i][k+1]\n",
    "        type_05_copy[i][58]=temp\n",
    "    if(i%100==0):\n",
    "        print(i,\"done\")\n",
    "    ans05.append(temp[0][0]/denominator)\n",
    "print(\"done all\")\n",
    "print(\"ans05:\",ans05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=pd.DataFrame()\n",
    "t['id']=test['id']\n",
    "t['span']=test['span']\n",
    "t['feature_ratio_type0']=ans00\n",
    "t['feature_ratio_type1']=ans01\n",
    "t['feature_ratio_type2']=ans02\n",
    "t['feature_ratio_type3']=ans03\n",
    "t['feature_ratio_type4']=ans04\n",
    "t['feature_ratio_type5']=ans05\n",
    "t.to_csv(\"competition_data/LSTM_test_feat_ratios.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_LSTM=pd.read_csv(\"competition_data/LSTM_test_feat_ratios.csv\")\n",
    "df_LSTM_test=t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.drop(\"id\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_LSTM_train.columns:\n",
    "    if df_LSTM_train[col].isnull().sum()>0:\n",
    "        df_LSTM_train[col].fillna(df_LSTM_train[col].mean,inplace=True)\n",
    "\n",
    "for col in df_LSTM_test.columns:\n",
    "    if df_LSTM_test[col].isnull().sum()>0:\n",
    "        df_LSTM_test[col].fillna(df_LSTM_test[col].mean,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=df_LSTM_train.iloc[:].values\n",
    "ytrain=df_original['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x=df_LSTM_test.iloc[:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_x=StandardScaler()\n",
    "xtrain=sc_x.fit_transform(xtrain)\n",
    "test_x=sc_x.transform(test_x)\n",
    "sc_y=StandardScaler()\n",
    "ytrain_scaled=sc_y.fit_transform(ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " wE NOW DEFINE OUR NEURAL NET TRAINED ON THE 6 FEATURE RATIOS OF TRAIN AND OUPUT PREDICTED ON TEST DATASET'S FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_model = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',input_dim = x.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model.add(Dense(128, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(64, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(32, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(16, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(8, kernel_initializer='normal',activation='relu'))\n",
    "# The Output Layer :\n",
    "NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_model.fit(xtrain, ytrain_scaled, epochs=1000000, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_model=load_model(\"weights/final_NN_over_LSTM.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred=sc_y.inverse_transform(NN_model.predict(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalcsv=pd.DataFrame()\n",
    "finalcsv['id']=df_LSTM_safe['id']\n",
    "finalcsv['target']=ypred\n",
    "finalcsv.to_csv(\"competition_data/LSTM_plus_NN1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pLEASE SUBMIT THE CSV THAT WILL BE CREATED ABOVE AND VERIFY"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
